{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c7b090c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  !pip install xgboost\n",
    "#  !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1b6401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.multioutput import MultiOutputRegressor\n",
    " \n",
    "# # Load the data\n",
    "# df = pd.read_csv('processed_102 1.csv')\n",
    " \n",
    "# # Split the data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df, test_size=0.25)\n",
    " \n",
    "# # Create a MultiOutputRegressor object\n",
    "# model = MultiOutputRegressor(estimator=LinearRegression())\n",
    " \n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    " \n",
    "# # Make predictions on new data\n",
    "# predictions = model.predict(X_test)\n",
    " \n",
    "# # Print the predictions\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\python311\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\satvik.madaan\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\python311\\lib\\site-packages (from scipy) (1.26.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.26.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib) (4.45.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satvik.madaan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python311\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\satvik.madaan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install scipy\n",
    "! pip install numpy\n",
    "! pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\python311\\lib\\site-packages (0.13.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\python311\\lib\\site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\python311\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in c:\\python311\\lib\\site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.45.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satvik.madaan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\satvik.madaan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn\n",
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10821b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c05b7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data-model-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac873711",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = df.drop(['Unnamed: 0'], axis =1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8846681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70645882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26a0d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix = df.corr()\n",
    "\n",
    "# # Print the correlation matrix\n",
    "# print(\"Correlation Matrix:\")\n",
    "# print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2265564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0df68c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5bb27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Bearer Setup Failure Voice%','TIMESTAMP'],axis=1)\n",
    "# columns_to_normalize = df.columns\n",
    "# Min-Max scaling (Normalization) using pandas\n",
    "# df[columns_to_normalize] = df[columns_to_normalize].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "881d1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c63d922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = df.columns.to_list()\n",
    "lst.remove('Avg_Connected_UEs')\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a446d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =df\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "predicted_values={}\n",
    "actual_values={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafefa0e",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efcb93a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                      MSE       R-squared \n",
      "--------------------------------------------------\n",
      "HO Failures                   0.029     -0.011    \n",
      "PRB Util%                     34.394    0.914     \n",
      "HQ_EXE_TOTARGET_FAILURE_QCI_1 0.001     0.052     \n",
      "DL Packet Loss Pct            0.164     0.006     \n",
      "Bearer Drop Voice%            0.036     -0.013    \n",
      "Bearer Drops                  0.965     0.095     \n",
      "RRC Setup Failures            3.842     0.550     \n",
      "HO_fail_InterFreq             0.104     -0.006    \n",
      "Combined RACH Failure%        0.001     0.460     \n",
      "Avg CQI                       0.415     0.661     \n",
      "QCI 1 Bearer Drop%            0.036     -0.013    \n",
      "ERAB Setup Fail%              0.001     0.061     \n",
      "HO Failure%                   0.001     -0.006    \n",
      "Bearer Drop%                  0.000     0.057     \n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    " \n",
    "# Define the independent variable (feature)\n",
    "\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    " \n",
    " \n",
    "# List of dependent variable column names\n",
    "\n",
    "dependent_variables = lst\n",
    " \n",
    "   \n",
    "# Iterate through dependent variables and perform Linear Regression\n",
    "\n",
    "for dependent_variable in dependent_variables:\n",
    "\n",
    "    # Define the current dependent variable\n",
    "\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "\n",
    "    linear_regressor = LinearRegression()\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "\n",
    "    linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "\n",
    "    test_predictions = linear_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    mse_scores[dependent_variable] = test_mse\n",
    "\n",
    "    r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "    # Store the predicted and actual values in dictionaries\n",
    "\n",
    "    predicted_values[dependent_variable] = test_predictions\n",
    "\n",
    "    actual_values[dependent_variable] = y_test.values\n",
    " \n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "\n",
    "for variable in lst:\n",
    "\n",
    "    print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n",
    "\n",
    "# print(\"\\nPredicted vs Actual values for the last dependent variable:\")\n",
    "\n",
    "# print(\"Predicted\\tActual\")\n",
    "\n",
    "# for i in range(len(predicted_values[lst[-1]])):\n",
    "\n",
    "#     print(f\"{predicted_values[lst[-1]][i]:.3f}\\t\\t{actual_values[lst[-1]][i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dd21e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking Input from the user \n",
    "\n",
    "# # Importing required libraries\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    " \n",
    "# # Load your data into the 'data' DataFrame\n",
    "\n",
    "# # ...\n",
    " \n",
    "# # Get user input for 'Avg_Connected_UEs' value\n",
    "\n",
    "# avg_connected_ue_value = float(input(\"Enter the value of Avg_Connected_UEs (between 16.1 to 84.5): \"))\n",
    " \n",
    "# # List of dependent variable column names\n",
    "\n",
    "# dependent_variables = lst\n",
    " \n",
    "# # Dictionary to store MSE and R-squared values for each dependent variable\n",
    "\n",
    "# results = {}\n",
    " \n",
    "# # Iterate through dependent variables and perform Linear Regression\n",
    "\n",
    "# for dependent_variable in dependent_variables:\n",
    "\n",
    "#     # Define the current dependent variable\n",
    "\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "#     # Prepare the input data for prediction\n",
    "\n",
    "#     X = pd.DataFrame({'Avg_Connected_UEs': [avg_connected_ue_value]})\n",
    "\n",
    "#     # Initialize the Linear Regression model\n",
    "\n",
    "#     linear_regressor = LinearRegression()\n",
    "\n",
    "#     # Train the model with the entire dataset\n",
    "\n",
    "#     linear_regressor.fit(data[['Avg_Connected_UEs']], y)\n",
    "\n",
    "#     # Predictions for the input 'Avg_Connected_UEs' value\n",
    "\n",
    "#     predicted_value = linear_regressor.predict(X)\n",
    "\n",
    "#     # Calculate MSE and R-squared for the current dependent variable\n",
    "\n",
    "#     mse = mean_squared_error(y, linear_regressor.predict(data[['Avg_Connected_UEs']]))\n",
    "\n",
    "#     r2 = r2_score(y, linear_regressor.predict(data[['Avg_Connected_UEs']]))\n",
    "\n",
    "#     # Store results in the dictionary\n",
    "\n",
    "#     results[dependent_variable] = {'MSE': mse, 'R-squared': r2, 'Predicted_Value': predicted_value[0]}\n",
    " \n",
    "# # Print results for all dependent variables\n",
    "\n",
    "# print(f\"{'Variable':<30}{'MSE':<15}{'R-squared':<15}{'Predicted Value'}\")\n",
    "\n",
    "# print('-' * 75)\n",
    "\n",
    "# for variable, values in results.items():\n",
    "\n",
    "#     print(f\"{variable:<30}{values['MSE']:<15.3f}{values['R-squared']:<15.3f}{values['Predicted_Value']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3917c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                      Predicted Value\n",
      "---------------------------------------------\n",
      "HO Failures                   0.006\n",
      "PRB Util%                     18.273\n",
      "HQ_EXE_TOTARGET_FAILURE_QCI_1 0.003\n",
      "DL Packet Loss Pct            0.111\n",
      "Bearer Drop Voice%            0.020\n",
      "Bearer Drops                  0.221\n",
      "RRC Setup Failures            0.725\n",
      "HO_fail_InterFreq             0.018\n",
      "Combined RACH Failure%        0.033\n",
      "Avg CQI                       9.741\n",
      "QCI 1 Bearer Drop%            0.020\n",
      "ERAB Setup Fail%              0.002\n",
      "HO Failure%                   0.001\n",
      "Bearer Drop%                  0.002\n"
     ]
    }
   ],
   "source": [
    "# Taking Input from the user UPDATED CODE\n",
    "\n",
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your data into the 'data' DataFrame\n",
    "# ...\n",
    "\n",
    "# Get user input for 'Avg_Connected_UEs' value\n",
    "avg_connected_ue_value = float(input(\"Enter the value of Avg_Connected_UEs (between 16.1 to 84.5): \"))\n",
    "\n",
    "# if(avg_connected_ue_value <=16.1 & avg_connected_ue_value>=84.5):\n",
    "#     continue\n",
    "# else:\n",
    "#     print(\"Enter the 'avg_connected_ue_value' in range\")\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Dictionary to store predicted values for each dependent variable\n",
    "results = {}\n",
    "\n",
    "# Iterate through dependent variables and perform Linear Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Prepare the input data for prediction\n",
    "    X = pd.DataFrame({'Avg_Connected_UEs': [avg_connected_ue_value]})\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    linear_regressor = LinearRegression()\n",
    "\n",
    "    # Train the model with the entire dataset\n",
    "    linear_regressor.fit(data[['Avg_Connected_UEs']], y)\n",
    "\n",
    "    # Predictions for the input 'Avg_Connected_UEs' value\n",
    "    predicted_value = linear_regressor.predict(X)\n",
    "\n",
    "    # Store results in the dictionary\n",
    "    results[dependent_variable] = predicted_value[0]\n",
    "\n",
    "# Print predicted values for all dependent variables\n",
    "print(f\"{'Variable':<30}{'Predicted Value'}\")\n",
    "print('-' * 45)\n",
    "\n",
    "for variable, predicted_value in results.items():\n",
    "    print(f\"{variable:<30}{predicted_value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5348dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                      Predicted Value\n",
      "---------------------------------------------\n",
      "Unnamed: 0                    61.140\n",
      "HO Failures                   0.001\n",
      "PRB Util%                     7.277\n",
      "HQ_EXE_TOTARGET_FAILURE_QCI_1 -0.001\n",
      "DL Packet Loss Pct            0.091\n",
      "Bearer Drop Voice%            0.015\n",
      "Bearer Drops                  0.066\n",
      "RRC Setup Failures            -0.454\n",
      "HO_fail_InterFreq             -0.010\n",
      "Combined RACH Failure%        0.018\n",
      "Avg CQI                       10.285\n",
      "QCI 1 Bearer Drop%            0.015\n",
      "ERAB Setup Fail%              -0.001\n",
      "HO Failure%                   0.000\n",
      "Bearer Drop%                  0.002\n"
     ]
    }
   ],
   "source": [
    "# Taking Input from the user UPDATED CODE\n",
    "\n",
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your data into the 'data' DataFrame\n",
    "# ...\n",
    "\n",
    "# Initialize a variable to check if input is within the range\n",
    "is_valid_input = False\n",
    "\n",
    "while not is_valid_input:\n",
    "    # Get user input for 'Avg_Connected_UEs' value\n",
    "    avg_connected_ue_value = float(input(\"Enter the value of Avg_Connected_UEs (between 16.1 to 84.5): \"))\n",
    "    \n",
    "    # Check if the input is within the specified range\n",
    "    if 16.1 <= avg_connected_ue_value <= 84.5:\n",
    "        is_valid_input = True\n",
    "    else:\n",
    "        print(\"Warning: Enter the 'avg_connected_ue_value' in the range of 16.1 to 84.5. Try again.\")\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Dictionary to store predicted values for each dependent variable\n",
    "results = {}\n",
    "\n",
    "# Iterate through dependent variables and perform Linear Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Prepare the input data for prediction\n",
    "    X = pd.DataFrame({'Avg_Connected_UEs': [avg_connected_ue_value]})\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    linear_regressor = LinearRegression()\n",
    "\n",
    "    # Train the model with the entire dataset\n",
    "    linear_regressor.fit(data[['Avg_Connected_UEs']], y)\n",
    "\n",
    "    # Predictions for the input 'Avg_Connected_UEs' value\n",
    "    predicted_value = linear_regressor.predict(X)\n",
    "\n",
    "    # Store results in the dictionary\n",
    "    results[dependent_variable] = predicted_value[0]\n",
    "\n",
    "# Print predicted values for all dependent variables\n",
    "print(f\"{'Variable':<30}{'Predicted Value'}\")\n",
    "print('-' * 45)\n",
    "\n",
    "for variable, predicted_value in results.items():\n",
    "    print(f\"{variable:<30}{predicted_value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "312f5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #user input\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Load your dataset into 'data'\n",
    "\n",
    "# # Prompt the user to enter the value of Avg_Connected_UEs\n",
    "# avg_connected_ues = float(input(\"Enter the value of Avg_Connected_UEs: \"))\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Create dictionaries to store MSE and R-squared values\n",
    "# mse_scores = {}\n",
    "# r2_scores = {}\n",
    "\n",
    "# # Iterate through dependent variables and perform Linear Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]\n",
    "\n",
    "#     # Create a DataFrame with the user input as the independent variable\n",
    "#     X = pd.DataFrame({'Avg_Connected_UEs': [avg_connected_ues]})\n",
    "\n",
    "#     # Initialize the Linear Regression model\n",
    "#     linear_regressor = LinearRegression()\n",
    "\n",
    "#     # Train the model with the entire dataset\n",
    "#     linear_regressor.fit(data[['Avg_Connected_UEs']], y)\n",
    "\n",
    "#     # Predict the value for the given Avg_Connected_UEs\n",
    "#     predicted_value = linear_regressor.predict(X)\n",
    "\n",
    "#     # Calculate R-squared value (since there's only one prediction, MSE is not needed)\n",
    "#     r_squared = r2_score(y, predicted_value)\n",
    "\n",
    "#     mse_scores[dependent_variable] = None  # No need to calculate MSE for a single prediction\n",
    "#     r2_scores[dependent_variable] = r_squared\n",
    "\n",
    "# # Print the results for the user-provided input\n",
    "# print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "# print('-' * 50)\n",
    "\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{mse_scores[variable]:<10}{'{:.3f}'.format(r2_scores[variable]):<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89d0dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Load your dataset into 'data'\n",
    "\n",
    "# # Prompt the user to enter the value of Avg_Connected_UEs\n",
    "# avg_connected_ues = float(input(\"Enter the value of Avg_Connected_UEs: \"))\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Create dictionaries to store MSE and R-squared values\n",
    "# mse_scores = {}\n",
    "# r2_scores = {}\n",
    "\n",
    "# # Iterate through dependent variables and perform Linear Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]\n",
    "\n",
    "#     # Create a DataFrame with the user input as the independent variable\n",
    "#     X = pd.DataFrame({'Avg_Connected_UEs': [avg_connected_ues]})\n",
    "\n",
    "#     # Initialize the Linear Regression model\n",
    "#     linear_regressor = LinearRegression()\n",
    "\n",
    "#     # Train the model with the entire dataset\n",
    "#     linear_regressor.fit(data[['Avg_Connected_UEs']], y)\n",
    "\n",
    "#     # Predict the value for the given Avg_Connected_UEs\n",
    "#     predicted_value = linear_regressor.predict(X)\n",
    "\n",
    "#     # Calculate R-squared value and MSE for the user-provided input\n",
    "#     r_squared = r2_score(y, predicted_value)\n",
    "#     mse = mean_squared_error(y, predicted_value)\n",
    "\n",
    "#     mse_scores[dependent_variable] = mse\n",
    "#     r2_scores[dependent_variable] = r_squared\n",
    "\n",
    "# # Print the results for the user-provided input\n",
    "# print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "# print('-' * 50)\n",
    "\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{'{:.3f}'.format(mse_scores[variable]):<10}{'{:.3f}'.format(r2_scores[variable]):<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f68d3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                      MSE       R-squared \n",
      "--------------------------------------------------\n",
      "HO Failures                   0.012     0.000     \n",
      "PRB Util%                     348.237   0.000     \n",
      "HQ_EXE_TOTARGET_FAILURE_QCI_1 0.000     0.000     \n",
      "DL Packet Loss Pct            0.531     0.000     \n",
      "Bearer Drop Voice%            0.069     0.000     \n",
      "Bearer Drops                  0.682     0.000     \n",
      "RRC Setup Failures            19.746    0.000     \n",
      "HO_fail_InterFreq             0.051     0.000     \n",
      "Combined RACH Failure%        0.002     0.000     \n",
      "Avg CQI                       1.150     0.000     \n",
      "QCI 1 Bearer Drop%            0.069     0.000     \n",
      "ERAB Setup Fail%              0.000     0.000     \n",
      "HO Failure%                   0.001     0.000     \n",
      "Bearer Drop%                  0.000     0.000     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset into 'data'\n",
    "\n",
    "# Prompt the user to enter the value of Avg_Connected_UEs\n",
    "avg_connected_ues = float(input(\"Enter the value of Avg_Connected_UEs: \"))\n",
    "\n",
    "lst= [\n",
    "    'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "    'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "    'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "]\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst  # You need to define 'lst'\n",
    "\n",
    "# Create dictionaries to store MSE and R-squared values\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "\n",
    "# Iterate through dependent variables and perform Linear Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]\n",
    "\n",
    "    # Create a DataFrame with the same number of rows as 'y' for the user input\n",
    "    X = pd.DataFrame({'Avg_Connected_UEs': [avg_connected_ues] * len(y)})\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    linear_regressor = LinearRegression()\n",
    "\n",
    "    # Train the model\n",
    "    linear_regressor.fit(X, y)\n",
    "\n",
    "    # Predict the values for the given Avg_Connected_UEs\n",
    "    predicted_values = linear_regressor.predict(X)\n",
    "\n",
    "    # Calculate R-squared value and MSE for the user-provided input\n",
    "    r_squared = r2_score(y, predicted_values)\n",
    "    mse = mean_squared_error(y, predicted_values)\n",
    "\n",
    "    mse_scores[dependent_variable] = mse\n",
    "    r2_scores[dependent_variable] = r_squared\n",
    "\n",
    "# Print the results for the user-provided input\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "\n",
    "for variable in lst:\n",
    "    print(f\"{variable:<30}{'{:.3f}'.format(mse_scores[variable]):<10}{'{:.3f}'.format(r2_scores[variable]):<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19a0e720",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preprocessed_102_new.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\satvik.madaan\\Desktop\\digital twin\\flask-server\\models\\Model-1\\model-1.ipynb Cell 27\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/satvik.madaan/Desktop/digital%20twin/flask-server/models/Model-1/model-1.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/satvik.madaan/Desktop/digital%20twin/flask-server/models/Model-1/model-1.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Load your dataset into 'data'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/satvik.madaan/Desktop/digital%20twin/flask-server/models/Model-1/model-1.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Replace 'your_data.csv' with the actual path to your dataset.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/satvik.madaan/Desktop/digital%20twin/flask-server/models/Model-1/model-1.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mpreprocessed_102_new.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/satvik.madaan/Desktop/digital%20twin/flask-server/models/Model-1/model-1.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Prompt the user to enter the value of Avg_Connected_UEs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/satvik.madaan/Desktop/digital%20twin/flask-server/models/Model-1/model-1.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m avg_connected_ues \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter the value of Avg_Connected_UEs: \u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preprocessed_102_new.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset into 'data'\n",
    "# Replace 'your_data.csv' with the actual path to your dataset.\n",
    "data = pd.read_csv('preprocessed_102_new.csv')\n",
    "\n",
    "# Prompt the user to enter the value of Avg_Connected_UEs\n",
    "avg_connected_ues = float(input(\"Enter the value of Avg_Connected_UEs: \"))\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = ['HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "    'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "    'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'] \n",
    "# Replace with your column names.\n",
    "\n",
    "# Create dictionaries to store MSE and R-squared values\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "\n",
    "# Iterate through dependent variables and perform Linear Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]\n",
    "\n",
    "    # Create a DataFrame with the user input as the independent variable\n",
    "    X = pd.DataFrame({'Avg_Connected_UEs': [avg_connected_ues] * len(y)})\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    linear_regressor = LinearRegression()\n",
    "\n",
    "    # Train the model\n",
    "    linear_regressor.fit(X, y)\n",
    "\n",
    "    # Predict the values for the given Avg_Connected_UEs\n",
    "    predicted_values = linear_regressor.predict(X)\n",
    "\n",
    "    # Calculate R-squared value and MSE\n",
    "    r_squared = r2_score(y, predicted_values)\n",
    "    mse = mean_squared_error(y, predicted_values)\n",
    "\n",
    "    mse_scores[dependent_variable] = mse\n",
    "    r2_scores[dependent_variable] = r_squared\n",
    "\n",
    "# Print the results for the user-provided input\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "\n",
    "for variable in dependent_variables:\n",
    "    print(f\"{variable:<30}{'{:.3f}'.format(mse_scores[variable]):<10}{'{:.3f}'.format(r2_scores[variable]):<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d8d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Variable', 'MSE', 'R-squared', 'Actual', 'Predicted'])\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform Linear Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    linear_regressor = LinearRegression()\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = linear_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    # Create a DataFrame for the current dependent variable\n",
    "    current_df = pd.DataFrame({'Variable': [dependent_variable],\n",
    "                               'MSE': [test_mse],\n",
    "                               'R-squared': [test_r_squared],\n",
    "                               'Actual': [y_test.values],\n",
    "                               'Predicted': [test_predictions]})\n",
    "\n",
    "    # Append the DataFrame to the results\n",
    "    results_df = pd.concat([results_df, current_df], ignore_index=True)\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302155e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create empty lists to store the results\n",
    "variables = []\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "average_actual_values = []\n",
    "average_predicted_values = []\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform Linear Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Linear Regression model\n",
    "    linear_regressor = LinearRegression()\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = linear_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    # Store the results in lists\n",
    "    variables.append(dependent_variable)\n",
    "    mse_scores.append(test_mse)\n",
    "    r2_scores.append(test_r_squared)\n",
    "    average_actual_values.append(y_test.mean())\n",
    "    average_predicted_values.append(test_predictions.mean())\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({'Variable': variables, 'MSE': mse_scores, 'R-squared': r2_scores,\n",
    "                           'Average Actual': average_actual_values, 'Average Predicted': average_predicted_values})\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b46c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore (input)\n",
    "# # Importing required libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # Load your dataset into a DataFrame (replace 'data.csv' with your dataset file)\n",
    "# data = pd.read_csv('preprocessed_102_new.csv')\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = data.columns.tolist()  # Replace with your list of dependent variable column names\n",
    "\n",
    "# # Create an empty dictionary to store the predicted values for each column\n",
    "# predicted_values = {}\n",
    "\n",
    "# # Define the independent variable (feature)\n",
    "# X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# # Iterate through dependent variables and perform Linear Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Skip the independent variable itself\n",
    "#     if dependent_variable == 'Avg_Connected_UEs':\n",
    "#         continue\n",
    "\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "#     # Initialize the Linear Regression model\n",
    "#     linear_regressor = LinearRegression()\n",
    "\n",
    "#     # Train the model\n",
    "#     linear_regressor.fit(X, y)\n",
    "\n",
    "#     # Predict values for the entire dataset\n",
    "#     predicted_values[dependent_variable] = linear_regressor.predict(X)\n",
    "\n",
    "# # Create a DataFrame to display the predicted values\n",
    "# predicted_df = pd.DataFrame(predicted_values)\n",
    "\n",
    "# # Print the predicted values for all columns\n",
    "# print(predicted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c38e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acd8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4374da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Provided KPI names\n",
    "kpi_names = [\n",
    "    'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "    'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "    'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "]\n",
    "\n",
    "# Provided actual and predicted values\n",
    "actual_values = [0.970588, 0.451923, 0.949580, 0.986878, 0.989641, 0.882353, 0.943228, 0.882353,\n",
    "                 0.812941, 0.389003, 0.989641, 0.947368, 0.977376, 0.882353]\n",
    "predicted_values = [0.991997, 0.417648, 0.968433, 0.981292, 0.992016, 0.920363, 0.944723, 0.959313, \n",
    "                    0.774263, 0.416496, 0.992016, 0.967370, 0.992007, 0.912135]\n",
    "\n",
    "# Create an array for the y-axis positions\n",
    "position = np.arange(len(kpi_names))\n",
    "\n",
    "# Set the figure size and create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actual_values, position, color='blue', label='Actual', marker='o', s=100)\n",
    "plt.scatter(predicted_values, position, color='red', label='Predicted', marker='x', s=100)\n",
    "\n",
    "# Set Y-axis labels to KPI names\n",
    "plt.yticks(position, kpi_names)\n",
    "\n",
    "# Add labels and a reference line\n",
    "plt.ylabel('KPI Names')\n",
    "plt.xlabel('Values')\n",
    "\n",
    "plt.title('Scatter Plot of Actual vs. Predicted Values for KPIs')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Provided KPI names\n",
    "# kpi_names = [\n",
    "#     'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "#     'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "#     'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "# ]\n",
    "\n",
    "# # Provided actual and predicted values\n",
    "# actual_values = [0.970588, 0.451923, 0.949580, 0.986878, 0.989641, 0.882353, 0.943228, 0.882353, 0.812941, 0.389003, 0.989641, 0.947368, 0.977376, 0.882353]\n",
    "# predicted_values = [0.991997, 0.417648, 0.968433, 0.981292, 0.992016, 0.920363, 0.944723, 0.959313, \n",
    "#                     0.774263, 0.416496, 0.992016, 0.967370, 0.992007, 0.912135]\n",
    "# # Create an array for the x-axis positions\n",
    "# position = np.arange(len(kpi_names))\n",
    "\n",
    "# # Set the figure size and create the scatter plot with different colors\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(position, actual_values, c='blue', label='Actual', marker='o', s=100)\n",
    "# plt.scatter(position, predicted_values, c='red', label='Predicted', marker='x', s=100)\n",
    "\n",
    "# # Set X-axis labels to KPI names\n",
    "# plt.xticks(position, kpi_names, rotation=90)\n",
    "\n",
    "# # Add labels and a reference line\n",
    "# plt.ylabel('Values')\n",
    "# plt.plot([min(position), max(position)], [min(actual_values), max(actual_values)], color='green', linestyle='--', label='45-degree Reference Line')\n",
    "\n",
    "# plt.title('Scatter Plot of Actual vs. Predicted Values for KPIs (SVM Model)')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Replace this with your actual dataset\n",
    "# # Assuming you have one input feature and multiple KPIs\n",
    "# X = np.random.rand(100, 1)  # Input feature\n",
    "# KPIs = {\n",
    "#     'HO Failures': X * 2 + np.random.rand(100, 1),\n",
    "#     'PRB Util%': X * 3 + np.random.rand(100, 1),\n",
    "#     'HQ_EXE_TOTARGET_FAILURE_QCI_1': X * 4 + np.random.rand(100, 1),\n",
    "#     'DL Packet Loss Pct': X * 2.5 + np.random.rand(100, 1),\n",
    "#     'Bearer Drop Voice%': X * 3.2 + np.random.rand(100, 1),\n",
    "#     'Bearer Drops': X * 2.8 + np.random.rand(100, 1),\n",
    "#     'RRC Setup Failures': X * 1.5 + np.random.rand(100, 1),\n",
    "#     'HO_fail_InterFreq': X * 2.7 + np.random.rand(100, 1),\n",
    "#     'Combined RACH Failure%': X * 4.2 + np.random.rand(100, 1),\n",
    "#     'Avg CQI': X * 3.6 + np.random.rand(100, 1),\n",
    "#     'QCI 1 Bearer Drop%': X * 2.3 + np.random.rand(100, 1),\n",
    "#     'ERAB Setup Fail%': X * 1.8 + np.random.rand(100, 1),\n",
    "#     'HO Failure%': X * 2.1 + np.random.rand(100, 1),\n",
    "#     'Bearer Drop%': X * 3.9 + np.random.rand(100, 1),\n",
    "# }\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# X_train, X_test, KPIs_train, KPIs_test = train_test_split(X, KPIs, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train a separate linear regression model for each KPI\n",
    "# models = {}\n",
    "# for kpi_name in KPIs_train:\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_train, KPIs_train[kpi_name])\n",
    "#     models[kpi_name] = model\n",
    "\n",
    "# # Evaluate the models and calculate MSE for each KPI\n",
    "# mse_scores = {}\n",
    "# for kpi_name in models:\n",
    "#     predictions = models[kpi_name].predict(X_test)\n",
    "#     mse = mean_squared_error(KPIs_test[kpi_name], predictions)\n",
    "#     mse_scores[kpi_name] = mse\n",
    "\n",
    "# # Function to predict KPI values given an input feature\n",
    "# def predict_kpi(kpi_name, input_feature):\n",
    "#     model = models.get(kpi_name)\n",
    "#     if model is not None:\n",
    "#         return model.predict([[input_feature]])[0]\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # Input from the user\n",
    "# input_feature = float(input(\"Enter the KPI unit: \"))\n",
    "# kpi_name = input(\"Enter the KPI name (e.g., HO Failures, PRB Util%, HQ_EXE_TOTARGET_FAILURE_QCI_1, etc.): \")\n",
    "\n",
    "# predicted_value = predict_kpi(kpi_name, input_feature)\n",
    "# if predicted_value is not None:\n",
    "#     print(f'Predicted {kpi_name} for input {input_feature}: {predicted_value}')\n",
    "#     print(f'MSE for {kpi_name}: {mse_scores.get(kpi_name, \"N/A\")}')\n",
    "# else:\n",
    "#     print(f'Invalid KPI name: {kpi_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming you already have the 'results_df' DataFrame containing the results\n",
    "# # Extract the average actual and predicted values\n",
    "# average_actual = results_df['Average Actual']\n",
    "# average_predicted = results_df['Average Predicted']\n",
    "\n",
    "# # Create a scatter plot\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(average_actual, average_predicted, color='blue', label='Scatter Plot')\n",
    "\n",
    "# # Add labels and a 45-degree reference line\n",
    "# plt.xlabel('Average Actual Values')\n",
    "# plt.ylabel('Average Predicted Values')\n",
    "# plt.plot([min(average_actual), max(average_actual)], [min(average_actual), max(average_actual)], color='red', linestyle='--', label='45-degree Reference Line')\n",
    "\n",
    "# plt.title('Scatter Plot of Average Actual vs. Average Predicted Values')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming you already have the 'results_df' DataFrame containing the results\n",
    "# # Extract the average actual and predicted values\n",
    "# average_actual = results_df['Average Actual']\n",
    "# average_predicted = results_df['Average Predicted']\n",
    "\n",
    "# # Create a scatter plot with different colors for actual and predicted values\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(average_actual, average_actual, color='blue', label='Actual', marker='o')\n",
    "# plt.scatter(average_actual, average_predicted, color='red', label='Predicted', marker='x')\n",
    "\n",
    "# # Add labels and a 45-degree reference line\n",
    "# plt.xlabel('Average Actual Values')\n",
    "# plt.ylabel('Average Predicted Values')\n",
    "# plt.plot([min(average_actual), max(average_actual)], [min(average_actual), max(average_actual)], color='green', linestyle='--', label='45-degree Reference Line')\n",
    "\n",
    "# plt.title('Scatter Plot of Average Actual vs. Average Predicted Values')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c14778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with the path to your dataset)\n",
    "data = pd.read_csv('preprocessed_102_new.csv')\n",
    "\n",
    "# Prompt the user to select the columns for which they want to calculate MSE\n",
    "selected_columns = input(\"Enter the column names (comma-separated) for which you want to calculate MSE: \").split(',')\n",
    "selected_columns = [col.strip() for col in selected_columns]\n",
    "\n",
    "# Prompt the user to enter the actual and predicted columns\n",
    "actual_column = input(\"Enter the column name with actual values: \").strip()\n",
    "predicted_column = input(\"Enter the column name with predicted values: \").strip()\n",
    "\n",
    "# Initialize a dictionary to store the MSE values for each selected column\n",
    "mse_values = {}\n",
    "\n",
    "# Calculate MSE for each selected column\n",
    "for column in selected_columns:\n",
    "    mse = mean_squared_error(data[actual_column], data[predicted_column])\n",
    "    mse_values[column] = mse\n",
    "\n",
    "# Display the MSE values for each selected column\n",
    "for column, mse in mse_values.items():\n",
    "    print(f\"MSE for '{column}': {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e140f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d70a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e14842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Initialize dictionaries to store predicted and actual values\n",
    "predicted_values = {}\n",
    "actual_values = {}\n",
    "\n",
    "# Iterate through dependent variables and perform Linear Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "    \n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize the Linear Regression model\n",
    "    linear_regressor = LinearRegression()\n",
    "    \n",
    "    # Train the model with 80% of the data\n",
    "    linear_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = linear_regressor.predict(X_test)\n",
    "    \n",
    "    # Store the predicted and actual values in dictionaries\n",
    "    predicted_values[dependent_variable] = test_predictions\n",
    "    actual_values[dependent_variable] = y_test.values  # Convert y_test to numpy array for easier indexing\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    mse_scores[dependent_variable] = test_mse\n",
    "    r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "# Print the results for the current dependent variable\n",
    "for variable in lst:\n",
    "    print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n",
    "\n",
    "# Print predicted and actual values for the last dependent variable (example)\n",
    "print(\"\\nPredicted vs Actual values for the last dependent variable:\")\n",
    "print(\"Predicted\\tActual\")\n",
    "for i in range(len(predicted_values[lst[-1]])):\n",
    "    print(f\"{predicted_values[lst[-1]][i]:.3f}\\t\\t{actual_values[lst[-1]][i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624fd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing required libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "# # Define the independent variable (feature)\n",
    "# X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Initialize dictionaries to store absolute errors\n",
    "# absolute_errors = {}\n",
    "\n",
    "\n",
    "# # Iterate through dependent variables and perform Linear Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "    \n",
    "#     # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Initialize the Linear Regression model\n",
    "#     linear_regressor = LinearRegression()\n",
    "    \n",
    "#     # Train the model with 80% of the data\n",
    "#     linear_regressor.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predictions on the test set (20% of the data)\n",
    "#     test_predictions = linear_regressor.predict(X_test)\n",
    "    \n",
    "    \n",
    "#     # Calculate the absolute errors using the provided formula\n",
    "#     absolute_errors[dependent_variable] = ((abs(y_test - test_predictions) / y_test).sum()) / len(y_test)\n",
    "    \n",
    "#     if(absolute_errors[dependent_variable]<0):\n",
    "#         absolute_errors[dependent_variable] = absolute_errors[dependent_variable] * (-1)\n",
    "\n",
    "# print(f\"{'Variable':<30}{'Average Absolute Error':<20}\")\n",
    "# print('-' * 50)\n",
    "# # Print the results for the current dependent variable\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{absolute_errors[variable]:<20.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt \n",
    "# plt.figure(figsize=(10, 8)) \n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\") \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44258f20",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing required libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Define the independent variable (feature)\n",
    "# X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Dictionary to store MSE and R-squared values for each dependent variable\n",
    "# mse_scores = {}\n",
    "# r2_scores = {}\n",
    "\n",
    "# # Iterate through dependent variables and perform SVM Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "    \n",
    "#     # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Initialize the SVM Regressor\n",
    "#     svm_regressor = SVR(kernel='linear')  # You can choose different kernels ('rbf', 'poly', etc.) based on your data\n",
    "    \n",
    "#     # Train the model with 80% of the data\n",
    "#     svm_regressor.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predictions on the test set (20% of the data)\n",
    "#     test_predictions = svm_regressor.predict(X_test)\n",
    "    \n",
    "#     # Calculate testing R-squared and testing MSE\n",
    "#     test_r_squared = r2_score(y_test, test_predictions)\n",
    "#     test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    \n",
    "#     mse_scores[dependent_variable] = test_mse\n",
    "#     r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "# # Print MSE and R-squared values for each dependent variable\n",
    "# print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "# print('-' * 50)\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def69db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE\n",
    "\n",
    "data =df\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "predicted_values={}\n",
    "actual_values={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model updated\n",
    "# SVM is not good as MSE is not close to zero and R-square is not close to one \n",
    "\n",
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform SVM Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the SVM model\n",
    "    svm_regressor = SVR(kernel='linear')\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    svm_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = svm_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    mse_scores[dependent_variable] = test_mse\n",
    "    r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "    # Store the predicted and actual values in dictionaries\n",
    "    predicted_values[dependent_variable] = test_predictions\n",
    "    actual_values[dependent_variable] = y_test.values\n",
    "\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "for variable in lst:\n",
    "    print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ff720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create empty lists to store the results\n",
    "variables = []\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "average_actual_values = []\n",
    "average_predicted_values = []\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform SVM regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the SVM regression model\n",
    "    svm_regressor = SVR()\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    svm_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = svm_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    # Store the results in lists\n",
    "    variables.append(dependent_variable)\n",
    "    mse_scores.append(test_mse)\n",
    "    r2_scores.append(test_r_squared)\n",
    "    average_actual_values.append(y_test.mean())\n",
    "    average_predicted_values.append(test_predictions.mean())\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({'Variable': variables, 'MSE': mse_scores, 'R-squared': r2_scores,\n",
    "                           'Average Actual': average_actual_values, 'Average Predicted': average_predicted_values})\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2956c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38c119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Provided KPI names\n",
    "kpi_names = [\n",
    "    'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "    'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "    'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "]\n",
    "\n",
    "# Provided actual and predicted values\n",
    "actual_values = [0.970588, 0.451923, 0.949580, 0.986878, 0.989641, 0.882353, 0.943228, 0.882353,\n",
    "                 0.812941, 0.389003, 0.989641, 0.947368, 0.977376, 0.882353]\n",
    "predicted_values = [0.907050, 0.433501, 0.902695, 0.902048, 0.907675, 0.899651, 0.901935, 0.902667, \n",
    "                    0.796953, 0.426961, 0.907675, 0.902678, 0.907050, 0.893758]\n",
    "\n",
    "\n",
    "# Create an array for the y-axis positions\n",
    "position = np.arange(len(kpi_names))\n",
    "\n",
    "# Set the figure size and create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actual_values, position, color='blue', label='Actual', marker='o', s=100)\n",
    "plt.scatter(predicted_values, position, color='red', label='Predicted', marker='x', s=100)\n",
    "\n",
    "# Set Y-axis labels to KPI names\n",
    "plt.yticks(position, kpi_names)\n",
    "\n",
    "# Add labels and a reference line\n",
    "plt.ylabel('KPI Names')\n",
    "plt.xlabel('Values')\n",
    "\n",
    "plt.title('Scatter Plot of Actual vs. Predicted Values for KPIs')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2da889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Provided KPI names\n",
    "# kpi_names = [\n",
    "#     'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "#     'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "#     'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "# ]\n",
    "\n",
    "# # Provided actual and predicted values\n",
    "# actual_values = [0.455970, 0.970588, 0.451923, 0.949580, 0.986878, 0.989641, 0.882353, 0.943228, 0.882353, 0.812941, 0.389003, 0.989641, 0.947368, 0.977376, 0.882353]\n",
    "# predicted_values = [0.907050, 0.433501, 0.902695, 0.902048, 0.907675, 0.899651, 0.901935, 0.902667, 0.796953, 0.426961, 0.907675, 0.902678, 0.907050, 0.893758]\n",
    "\n",
    "# # Create an array for the y-axis positions\n",
    "# position = np.arange(len(kpi_names))\n",
    "\n",
    "# # Set the figure size and create the scatter plot with different colors\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(actual_values, position, c='blue', label='Actual', marker='o', s=100)\n",
    "# plt.scatter(predicted_values, position, c='red', label='Predicted', marker='x', s=100)\n",
    "\n",
    "# # Set Y-axis labels to KPI names\n",
    "# plt.yticks(position, kpi_names)\n",
    "\n",
    "# # Add labels and a reference line\n",
    "# plt.xlabel('Values')\n",
    "# plt.plot([min(actual_values), max(actual_values)], [min(position), max(position)], color='green', linestyle='--', label='45-degree Reference Line')\n",
    "\n",
    "# plt.title('Scatter Plot of Actual vs. Predicted Values for KPIs (SVM Model)')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e15caf0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8069fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing required libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# # Define the independent variable (feature)\n",
    "# X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Dictionary to store MSE and R-squared values for each dependent variable\n",
    "# mse_scores = {}\n",
    "# r2_scores = {}\n",
    "\n",
    "# # Iterate through dependent variables and perform Random Forest Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "    \n",
    "#     # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Initialize the Random Forest Regressor\n",
    "#     rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust hyperparameters\n",
    "    \n",
    "#     # Train the model with 80% of the data\n",
    "#     rf_regressor.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predictions on the test set (20% of the data)\n",
    "#     test_predictions = rf_regressor.predict(X_test)\n",
    "    \n",
    "#     # Calculate testing R-squared and testing MSE\n",
    "#     test_r_squared = r2_score(y_test, test_predictions)\n",
    "#     test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    \n",
    "#     mse_scores[dependent_variable] = test_mse\n",
    "#     r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "# # Print MSE and R-squared values for each dependent variable\n",
    "# print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "# print('-' * 50)\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE\n",
    "\n",
    "data =df\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "predicted_values={}\n",
    "actual_values={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform Random Forest Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest model\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = rf_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    mse_scores[dependent_variable] = test_mse\n",
    "    r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "    # Store the predicted and actual values in dictionaries\n",
    "    predicted_values[dependent_variable] = test_predictions\n",
    "    actual_values[dependent_variable] = y_test.values\n",
    "\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "for variable in lst:\n",
    "    print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create empty lists to store the results\n",
    "variables = []\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "average_actual_values = []\n",
    "average_predicted_values = []\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform Random Forest regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest regression model\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust the number of estimators as needed\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = rf_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    # Store the results in lists\n",
    "    variables.append(dependent_variable)\n",
    "    mse_scores.append(test_mse)\n",
    "    r2_scores.append(test_r_squared)\n",
    "    average_actual_values.append(y_test.mean())\n",
    "    average_predicted_values.append(test_predictions.mean())\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({'Variable': variables, 'MSE': mse_scores, 'R-squared': r2_scores,\n",
    "                           'Average Actual': average_actual_values, 'Average Predicted': average_predicted_values})\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a25072",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing required libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Define the independent variable (feature)\n",
    "# X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Dictionary to store MSE and R-squared values for each dependent variable\n",
    "# mse_scores = {}\n",
    "# r2_scores = {}\n",
    "\n",
    "# # Iterate through dependent variables and perform KNN Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "    \n",
    "#     # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Initialize the KNN Regressor (with k=5 as an example, you can adjust the value of k)\n",
    "#     knn_regressor = KNeighborsRegressor(n_neighbors=5)  \n",
    "    \n",
    "#     # Train the model with 80% of the data\n",
    "#     knn_regressor.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predictions on the test set (20% of the data)\n",
    "#     test_predictions = knn_regressor.predict(X_test)\n",
    "    \n",
    "#     # Calculate testing R-squared and testing MSE\n",
    "#     test_r_squared = r2_score(y_test, test_predictions)\n",
    "#     test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    \n",
    "#     mse_scores[dependent_variable] = test_mse\n",
    "#     r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "# # Print MSE and R-squared values for each dependent variable\n",
    "# print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "# print('-' * 50)\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b95dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE\n",
    "\n",
    "data =df\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "predicted_values={}\n",
    "actual_values={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform KNN Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the KNN model\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors (5 in this example)\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = knn_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    mse_scores[dependent_variable] = test_mse\n",
    "    r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "    # Store the predicted and actual values in dictionaries\n",
    "    predicted_values[dependent_variable] = test_predictions\n",
    "    actual_values[dependent_variable] = y_test.values\n",
    "\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "for variable in lst:\n",
    "    print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98208d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create empty lists to store the results\n",
    "variables = []\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "average_actual_values = []\n",
    "average_predicted_values = []\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform KNN regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the KNN regression model with a specified number of neighbors (e.g., n_neighbors=5)\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = knn_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    # Store the results in lists\n",
    "    variables.append(dependent_variable)\n",
    "    mse_scores.append(test_mse)\n",
    "    r2_scores.append(test_r_squared)\n",
    "    average_actual_values.append(y_test.mean())\n",
    "    average_predicted_values.append(test_predictions.mean())\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({'Variable': variables, 'MSE': mse_scores, 'R-squared': r2_scores,\n",
    "                           'Average Actual': average_actual_values, 'Average Predicted': average_predicted_values})\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae057d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b06c61c0",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing required libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# # Define the independent variable (feature)\n",
    "# X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Dictionary to store MSE and R-squared values for each dependent variable\n",
    "# mse_scores = {}\n",
    "# r2_scores = {}\n",
    "\n",
    "# # Iterate through dependent variables and perform Decision Tree Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "    \n",
    "#     # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Initialize the Decision Tree Regressor\n",
    "#     dt_regressor = DecisionTreeRegressor(random_state=42)  # You can adjust hyperparameters\n",
    "    \n",
    "#     # Train the model with 80% of the data\n",
    "#     dt_regressor.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predictions on the test set (20% of the data)\n",
    "#     test_predictions = dt_regressor.predict(X_test)\n",
    "    \n",
    "#     # Calculate testing R-squared and testing MSE\n",
    "#     test_r_squared = r2_score(y_test, test_predictions)\n",
    "#     test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    \n",
    "#     mse_scores[dependent_variable] = test_mse\n",
    "#     r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "# # Print MSE and R-squared values for each dependent variable\n",
    "# print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "# print('-' * 50)\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE\n",
    "data =df\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "predicted_values={}\n",
    "actual_values={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50170b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform Decision Tree Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Decision Tree model\n",
    "    decision_tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    decision_tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = decision_tree_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    mse_scores[dependent_variable] = test_mse\n",
    "    r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "    # Store the predicted and actual values in dictionaries\n",
    "    predicted_values[dependent_variable] = test_predictions\n",
    "    actual_values[dependent_variable] = y_test.values\n",
    "\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "for variable in lst:\n",
    "    print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create empty lists to store the results\n",
    "variables = []\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "average_actual_values = []\n",
    "average_predicted_values = []\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform Decision Tree regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Decision Tree regression model\n",
    "    tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = tree_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    # Store the results in lists\n",
    "    variables.append(dependent_variable)\n",
    "    mse_scores.append(test_mse)\n",
    "    r2_scores.append(test_r_squared)\n",
    "    average_actual_values.append(y_test.mean())\n",
    "    average_predicted_values.append(test_predictions.mean())\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({'Variable': variables, 'MSE': mse_scores, 'R-squared': r2_scores,\n",
    "                           'Average Actual': average_actual_values, 'Average Predicted': average_predicted_values})\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb28cfa",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46534aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing required libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Load your dataset\n",
    "# data = pd.read_csv('processed_102.csv')\n",
    "\n",
    "# # Define the independent variable (feature)\n",
    "# X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Dictionary to store MSE and R-squared values for each dependent variable\n",
    "# mse_scores = {}\n",
    "# r2_scores = {}\n",
    "\n",
    "# # Iterate through dependent variables and perform Gradient Boosting Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "    \n",
    "#     # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Initialize the Gradient Boosting Regressor\n",
    "#     gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)  # You can adjust hyperparameters\n",
    "    \n",
    "#     # Train the model with 80% of the data\n",
    "#     gb_regressor.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predictions on the test set (20% of the data)\n",
    "#     test_predictions = gb_regressor.predict(X_test)\n",
    "    \n",
    "#     # Calculate testing accuracy (R-squared) and testing MSE\n",
    "#     test_r_squared = r2_score(y_test, test_predictions)\n",
    "#     test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    \n",
    "#     mse_scores[dependent_variable] = test_mse\n",
    "#     r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "# # Print MSE and R-squared values for each dependent variable\n",
    "# print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "# print('-' * 50)\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE\n",
    "data =df\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "predicted_values={}\n",
    "actual_values={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54c1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform Decision Tree Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Decision Tree model\n",
    "    decision_tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    decision_tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = decision_tree_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    mse_scores[dependent_variable] = test_mse\n",
    "    r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "    # Store the predicted and actual values in dictionaries\n",
    "    predicted_values[dependent_variable] = test_predictions\n",
    "    actual_values[dependent_variable] = y_test.values\n",
    "\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "for variable in lst:\n",
    "    print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a50632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create empty lists to store the results\n",
    "variables = []\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "average_actual_values = []\n",
    "average_predicted_values = []\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform Gradient Boosting Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Gradient Boosting Regression model\n",
    "    gb_regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)  # You can adjust the number of estimators as needed\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = gb_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    # Store the results in lists\n",
    "    variables.append(dependent_variable)\n",
    "    mse_scores.append(test_mse)\n",
    "    r2_scores.append(test_r_squared)\n",
    "    average_actual_values.append(y_test.mean())\n",
    "    average_predicted_values.append(test_predictions.mean())\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({'Variable': variables, 'MSE': mse_scores, 'R-squared': r2_scores,\n",
    "                           'Average Actual': average_actual_values, 'Average Predicted': average_predicted_values})\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad264524",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE\n",
    "data =df\n",
    "mse_scores = {}\n",
    "r2_scores = {}\n",
    "predicted_values={}\n",
    "actual_values={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform AdaBoost Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the AdaBoost model\n",
    "    adaboost_regressor = AdaBoostRegressor(random_state=42)\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    adaboost_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = adaboost_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    mse_scores[dependent_variable] = test_mse\n",
    "    r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "    # Store the predicted and actual values in dictionaries\n",
    "    predicted_values[dependent_variable] = test_predictions\n",
    "    actual_values[dependent_variable] = y_test.values\n",
    "\n",
    "print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "print('-' * 50)\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "for variable in lst:\n",
    "    print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create empty lists to store the results\n",
    "variables = []\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "average_actual_values = []\n",
    "average_predicted_values = []\n",
    "\n",
    "# Define the independent variable (feature)\n",
    "X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# List of dependent variable column names\n",
    "dependent_variables = lst\n",
    "\n",
    "# Iterate through dependent variables and perform AdaBoost Regression\n",
    "for dependent_variable in dependent_variables:\n",
    "    # Define the current dependent variable\n",
    "    y = data[dependent_variable]  # Dependent variable\n",
    "\n",
    "    # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the AdaBoost Regression model\n",
    "    adaboost_regressor = AdaBoostRegressor(n_estimators=100, random_state=42)  # You can adjust the number of estimators as needed\n",
    "\n",
    "    # Train the model with 80% of the data\n",
    "    adaboost_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set (20% of the data)\n",
    "    test_predictions = adaboost_regressor.predict(X_test)\n",
    "\n",
    "    # Calculate testing R-squared and testing MSE\n",
    "    test_r_squared = r2_score(y_test, test_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "    # Store the results in lists\n",
    "    variables.append(dependent_variable)\n",
    "    mse_scores.append(test_mse)\n",
    "    r2_scores.append(test_r_squared)\n",
    "    average_actual_values.append(y_test.mean())\n",
    "    average_predicted_values.append(test_predictions.mean())\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({'Variable': variables, 'MSE': mse_scores, 'R-squared': r2_scores,\n",
    "                           'Average Actual': average_actual_values, 'Average Predicted': average_predicted_values})\n",
    "\n",
    "# Print the results for the current dependent variable\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00401ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing required libraries\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import AdaBoostRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Load your dataset\n",
    "# data = pd.read_csv('processed_102.csv')\n",
    "\n",
    "# # Define the independent variable (feature)\n",
    "# X = data[['Avg_Connected_UEs']]  # Independent variable (feature)\n",
    "\n",
    "# # List of dependent variable column names\n",
    "# dependent_variables = lst\n",
    "\n",
    "# # Dictionary to store MSE and R-squared values for each dependent variable\n",
    "# mse_scores = {}\n",
    "# r2_scores = {}\n",
    "\n",
    "# # Iterate through dependent variables and perform AdaBoost Regression\n",
    "# for dependent_variable in dependent_variables:\n",
    "#     # Define the current dependent variable\n",
    "#     y = data[dependent_variable]  # Dependent variable\n",
    "    \n",
    "#     # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Initialize the AdaBoost Regressor\n",
    "#     adaboost_regressor = AdaBoostRegressor(n_estimators=50, random_state=42)  # You can adjust hyperparameters\n",
    "    \n",
    "#     # Train the model with 80% of the data\n",
    "#     adaboost_regressor.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predictions on the test set (20% of the data)\n",
    "#     test_predictions = adaboost_regressor.predict(X_test)\n",
    "    \n",
    "#     # Calculate testing accuracy (R-squared) and testing MSE\n",
    "#     test_r_squared = r2_score(y_test, test_predictions)\n",
    "#     test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    \n",
    "#     mse_scores[dependent_variable] = test_mse\n",
    "#     r2_scores[dependent_variable] = test_r_squared\n",
    "\n",
    "# # Print MSE and R-squared values for each dependent variable\n",
    "# print(f\"{'Variable':<30}{'MSE':<10}{'R-squared':<10}\")\n",
    "# print('-' * 50)\n",
    "# for variable in lst:\n",
    "#     print(f\"{variable:<30}{mse_scores[variable]:<10.3f}{r2_scores[variable]:<10.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358c19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ae74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Provided KPI names\n",
    "kpi_names = [\n",
    "    'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "    'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "    'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "]\n",
    "\n",
    "# Provided predicted values for each model (replace with your data)\n",
    "predicted_values = [\n",
    "    [0.991997, 0.417648, 0.968433, 0.981292, 0.992016, 0.920363, 0.944723, 0.959313, \n",
    "                    0.774263, 0.416496, 0.992016, 0.967370, 0.992007, 0.912135],\n",
    "    [0.907050, 0.433501, 0.902695, 0.902048, 0.907675, 0.899651, 0.901935, 0.902667, 0.796953, 0.426961, 0.907675, 0.902678, 0.907050, 0.893758]\n",
    "    # Add predicted values for other models here\n",
    "]\n",
    "\n",
    "# Create an array for the x-axis positions\n",
    "position = np.arange(len(kpi_names))\n",
    "\n",
    "# Set the figure size and create the scatter plot with different colors for each model\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, model_predicted in enumerate(predicted_values):\n",
    "    plt.scatter(model_predicted, position, label=f'Model {i + 1}', s=100)\n",
    "\n",
    "# Set Y-axis labels to KPI names\n",
    "plt.yticks(position, kpi_names)\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel('Predicted Values')\n",
    "\n",
    "plt.title('Grouped Scatter Plot of Predicted Values for KPIs (Multiple Models)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d30493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Provided KPI names\n",
    "# kpi_names = [\n",
    "#     'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "#     'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "#     'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "# ]\n",
    "\n",
    "# # Provided predicted values for each model (replace with your data)\n",
    "# predicted_values = [\n",
    "#     [0.907050, 0.433501, 0.902695, 0.902048, 0.907675, 0.899651, 0.901935, 0.902667, 0.796953, 0.426961, 0.907675, 0.902678, 0.907050, 0.893758],\n",
    "#     # Add predicted values for other models here\n",
    "# ]\n",
    "\n",
    "# # Create an array for the y-axis positions\n",
    "# position = np.arange(len(kpi_names))\n",
    "\n",
    "# # Set the figure size and create the horizontal grouped scatter plot with different colors for each model\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for i, model_predicted in enumerate(predicted_values):\n",
    "#     plt.scatter(model_predicted, position, label=f'Model {i + 1}', s=100)\n",
    "\n",
    "# # Set X-axis labels to KPI names\n",
    "# plt.xticks(position, kpi_names, rotation=90)\n",
    "\n",
    "# # Add labels\n",
    "# plt.ylabel('Predicted Values')\n",
    "\n",
    "# plt.title('Horizontal Grouped Scatter Plot of Predicted Values for KPIs (Multiple Models)')\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Provided KPI names\n",
    "kpi_names = [\n",
    "    'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "    'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "    'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "]\n",
    "\n",
    "# Provided actual and predicted values for seven models (sample data)\n",
    "models = ['Linear Regression', 'SVM', 'Random Forest', 'KNN', 'Decision Tree', 'Gradient Boosting Regression', 'Adaboost']\n",
    "\n",
    "actual_values = [0.970588, 0.451923, 0.949580, 0.986878, 0.989641, 0.882353, \n",
    "                 0.943228, 0.882353, 0.812941, 0.389003, 0.989641, 0.947368, 0.977376, 0.882353]\n",
    "predicted_values = [\n",
    "    [0.991997, 0.417648, 0.968433, 0.981292, 0.992016, 0.920363, 0.944723, 0.959313, \n",
    "                    0.774263, 0.416496, 0.992016, 0.967370, 0.992007, 0.912135],\n",
    "    [0.907050, 0.433501, 0.902695, 0.902048, 0.907675, 0.899651, 0.901935, 0.902667, 0.796953, 0.426961, \n",
    "     0.907675, 0.902678, 0.907050, 0.893758],\n",
    "    [\n",
    "    0.999118, 0.412865, 0.967427, 0.984811,\n",
    "    0.965049, 0.922981, 0.962768, 0.953529, 0.814776,\n",
    "    0.430286, 0.965049, 0.965268, 0.999118, 0.914756],\n",
    "    [\n",
    "    0.994118, 0.421304, 0.966947, 0.985216,\n",
    "    0.987682, 0.931765, 0.954309, 0.952941, 0.788941,\n",
    "    0.423376, 0.987682, 0.965325, 0.994118, 0.920588],\n",
    "    \n",
    "    [\n",
    "    1.000000, 0.413132, 0.967087, 0.978081,\n",
    "    0.940170, 0.902941, 0.963064, 0.941176, 0.829412,\n",
    "    0.432289, 0.940170, 0.965170, 1.000000, 0.893382],\n",
    "    \n",
    "    [\n",
    "    1.000000, 0.417522, 0.967805, 0.978796,\n",
    "    0.940471, 0.910015, 0.966418, 0.942163, 0.815819,\n",
    "    0.421021, 0.940471, 0.965700, 1.000000, 0.898395],\n",
    "    \n",
    "    [\n",
    "    1.000000, 0.427790, 0.953508, 0.964764,\n",
    "    0.939890, 0.878799, 0.940486, 0.891039, 0.766014,\n",
    "    0.429942, 0.939890, 0.954437, 1.000000, 0.862930]\n",
    "    \n",
    "    \n",
    "    # Add predicted values for other models here\n",
    "]\n",
    "\n",
    "# Create an array for the x-axis positions\n",
    "position = np.arange(len(kpi_names))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a scatter plot for each model with different colors\n",
    "plt.scatter(position, actual_values, label=f'Actual', marker='o', s=100)\n",
    "for i, model_name in enumerate(models):\n",
    "    \n",
    "    plt.scatter(position, predicted_values[i], label=f'({model_name})', marker='x', s=100)\n",
    "\n",
    "# Set X-axis labels to KPI names\n",
    "plt.xticks(position, kpi_names, rotation=90)\n",
    "\n",
    "# Add labels and a reference line\n",
    "plt.ylabel('Values')\n",
    "plt.title('Scatter Plot of Actual vs. Predicted Values for KPIs (Multiple Models)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Provided KPI names\n",
    "# kpi_names = [\n",
    "#     'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "#     'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "#     'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "# ]\n",
    "\n",
    "# # Provided actual values and multiple sets of predicted values for seven models\n",
    "# actual_values = [0.970588, 0.451923, 0.949580, 0.986878, 0.989641, 0.882353, 0.943228, \n",
    "#                  0.882353, 0.812941, 0.389003, 0.989641, 0.947368, 0.977376, 0.882353]\n",
    "\n",
    "# predicted_values = [\n",
    "#     [0.991997, 0.417648, 0.968433, 0.981292, 0.992016, 0.920363, 0.944723, 0.959313, \n",
    "#      0.774263, 0.416496, 0.992016, 0.967370, 0.992007, 0.912135],\n",
    "#     [0.907050, 0.433501, 0.902695, 0.902048, 0.907675, 0.899651, 0.901935, 0.902667, 0.796953, 0.426961, \n",
    "#      0.907675, 0.902678, 0.907050, 0.893758],\n",
    "#     [\n",
    "#     0.999118, 0.412865, 0.967427, 0.984811,\n",
    "#     0.965049, 0.922981, 0.962768, 0.953529, 0.814776,\n",
    "#     0.430286, 0.965049, 0.965268, 0.999118, 0.914756],\n",
    "#     [\n",
    "#     0.994118, 0.421304, 0.966947, 0.985216,\n",
    "#     0.987682, 0.931765, 0.954309, 0.952941, 0.788941,\n",
    "#     0.423376, 0.987682, 0.965325, 0.994118, 0.920588],\n",
    "    \n",
    "#     [\n",
    "#     1.000000, 0.413132, 0.967087, 0.978081,\n",
    "#     0.940170, 0.902941, 0.963064, 0.941176, 0.829412,\n",
    "#     0.432289, 0.940170, 0.965170, 1.000000, 0.893382],\n",
    "    \n",
    "#     [\n",
    "#     1.000000, 0.417522, 0.967805, 0.978796,\n",
    "#     0.940471, 0.910015, 0.966418, 0.942163, 0.815819,\n",
    "#     0.421021, 0.940471, 0.965700, 1.000000, 0.898395],\n",
    "    \n",
    "#     [\n",
    "#     1.000000, 0.427790, 0.953508, 0.964764,\n",
    "#     0.939890, 0.878799, 0.940486, 0.891039, 0.766014,\n",
    "#     0.429942, 0.939890, 0.954437, 1.000000, 0.862930]\n",
    "    \n",
    "    \n",
    "#     # Add predicted values for other models here\n",
    "# ]\n",
    "\n",
    "# # Create an array for the x-axis positions\n",
    "# position = np.arange(len(kpi_names))\n",
    "\n",
    "# # Set the figure size and create the scatter plot with different colors for each model\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# # Plot actual values\n",
    "# plt.scatter(position, [actual_values] * len(kpi_names), c='blue', label='Actual', marker='o', s=100)\n",
    "\n",
    "# # Plot predicted values for each model with different colors\n",
    "# colors = ['red', 'green', 'purple', 'orange', 'brown', 'pink', 'gray']  # Define colors for each model\n",
    "# model_names = ['Linear Regression', 'SVM', 'Random Forest', 'KNN', 'Decision Tree', 'Gradient Boosting Regression', 'Adaboost']  # Model names\n",
    "\n",
    "# for i, predicted_values in enumerate(predicted_values_list):\n",
    "#     plt.scatter(position, predicted_values, c=colors[i], label=model_names[i], marker='x', s=100)\n",
    "\n",
    "# # Set X-axis labels to KPI names\n",
    "# plt.xticks(position, kpi_names, rotation=90)\n",
    "\n",
    "# # Add labels and a reference line\n",
    "# plt.ylabel('Values')\n",
    "# plt.title('Scatter Plot of Actual vs. Predicted Values for KPIs')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37122bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE for different KPIs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Provided KPI names\n",
    "kpi_names = [\n",
    "    'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "    'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "    'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "]\n",
    "\n",
    "# Provided actual and predicted values for seven models (sample data)\n",
    "models = ['Linear Regression', 'SVM', 'Random Forest', 'KNN', 'Decision Tree', 'Gradient Boosting Regression', 'Adaboost']\n",
    "\n",
    "# actual_values = [0.970588, 0.451923, 0.949580, 0.986878, 0.989641, 0.882353, \n",
    "#                  0.943228, 0.882353, 0.812941, 0.389003, 0.989641, 0.947368, 0.977376, 0.882353]\n",
    "predicted_values = [\n",
    "    [\n",
    "        0.028848, 0.006583, 0.027802, 0.002637, 0.003413, 0.038597, 0.002078,\n",
    "        0.104437, 0.013343, 0.019625, 0.003413, 0.027850, 0.016989, 0.038967\n",
    "    ],\n",
    "    [\n",
    "        0.032374, 0.007969, 0.032005, 0.009870, 0.010119, 0.042629, 0.005349,\n",
    "        0.103578, 0.012805, 0.021830, 0.010119, 0.032056, 0.021678, 0.040542\n",
    "    ],\n",
    "    [\n",
    "        0.029438, 0.011157, 0.032630, 0.004490, 0.023269, 0.056037, 0.002779,\n",
    "        0.127135, 0.018644, 0.028781, 0.023269, 0.032993, 0.017430, 0.060217\n",
    "    ],\n",
    "    [\n",
    "        0.030588, 0.009740, 0.029745, 0.003882, 0.005831, 0.040847, 0.003923,\n",
    "        0.091765, 0.018677, 0.020846, 0.005831, 0.029995, 0.018580, 0.046176\n",
    "    ],\n",
    "    [\n",
    "        0.029412, 0.013992, 0.036298, 0.007212, 0.062308, 0.080294, 0.003420,\n",
    "        0.176471, 0.027012, 0.040994, 0.062308, 0.036765, 0.017403, 0.088695\n",
    "    ],\n",
    "    [\n",
    "        0.029412, 0.011377, 0.034444, 0.006539, 0.061911, 0.058436, 0.002940,\n",
    "        0.170373, 0.020361, 0.026159, 0.061911, 0.035010, 0.017403, 0.065101\n",
    "    ],\n",
    "    [\n",
    "        0.029412, 0.010314, 0.030996, 0.003697, 0.062299, 0.039473, 0.001740,\n",
    "        0.140562, 0.017786, 0.016456, 0.062299, 0.030760, 0.017403, 0.044031\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Create an array for the x-axis positions\n",
    "position = np.arange(len(kpi_names))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a scatter plot for each model with different colors\n",
    "#plt.scatter(position, actual_values, label=f'Actual', marker='o', s=100)\n",
    "for i, model_name in enumerate(models):\n",
    "    \n",
    "    plt.scatter(position, predicted_values[i], label=f'({model_name})', marker='x', s=100)\n",
    "\n",
    "# Set X-axis labels to KPI names\n",
    "plt.xticks(position, kpi_names, rotation=90)\n",
    "\n",
    "# Add labels and a reference line\n",
    "plt.ylabel('Values')\n",
    "plt.title('MSE for KPIs (Multiple Models)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE for different KPIs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Provided KPI names\n",
    "kpi_names = [\n",
    "    'HO Failures', 'PRB Util%', 'HQ_EXE_TOTARGET_FAILURE_QCI_1', 'DL Packet Loss Pct',\n",
    "    'Bearer Drop Voice%', 'Bearer Drops', 'RRC Setup Failures', 'HO_fail_InterFreq',\n",
    "    'Combined RACH Failure%', 'Avg CQI', 'QCI 1 Bearer Drop%', 'ERAB Setup Fail%', 'HO Failure%', 'Bearer Drop%'\n",
    "]\n",
    "\n",
    "# Provided actual and predicted values for seven models (sample data)\n",
    "models = ['Linear Regression', 'SVM', 'Random Forest', 'KNN', 'Decision Tree', 'Gradient Boosting Regression', 'Adaboost']\n",
    "\n",
    "# actual_values = [0.970588, 0.451923, 0.949580, 0.986878, 0.989641, 0.882353, \n",
    "#                  0.943228, 0.882353, 0.812941, 0.389003, 0.989641, 0.947368, 0.977376, 0.882353]\n",
    "predicted_values = [\n",
    "    [\n",
    "        -0.010539, 0.914060, 0.052340, 0.005682, -0.013241, 0.094610, 0.550108,\n",
    "        -0.006072, 0.460366, 0.661152, -0.013241, 0.060897, -0.005773, 0.056621,\n",
    "    ],\n",
    "    [-0.134063, 0.895969, -0.090937, -2.721804, -2.004116, 0.000016, -0.158092, \n",
    "     0.002203, 0.482134, 0.623078, -2.004116, -0.080933, -0.283380, 0.018504\n",
    "    ],\n",
    "    [-0.031230, 0.854352, -0.112227, -0.693026, -5.908112, -0.314504, 0.398281, \n",
    "     -0.224737, 0.246015, 0.503048, -5.908112, -0.112532, -0.031870, -0.457818],\n",
    "    \n",
    "    [-0.071515, 0.872854, -0.013907, -0.463835, -0.731054, 0.041818, 0.150775,\n",
    "      0.116000, 0.244673, 0.640068, -0.731054, -0.011429, -0.099952, -0.117906],\n",
    "    \n",
    "    [-0.030303, 0.817343, -0.237263, -1.719510, -17.498283, -0.883523, 0.259597,\n",
    "     -0.700000, -0.092415, 0.292182, -17.498283, -0.239698, -0.030303, -1.147251],\n",
    "    \n",
    "    [-0.030303, 0.851479, -0.174058, -1.465665, -17.380625, -0.370768, 0.363511,\n",
    "     -0.641261, 0.176546, 0.548328, -17.380625, -0.180518, -0.030302, -0.576059 ],\n",
    "    \n",
    "    [-0.030303, 0.865362, -0.056532, -0.394237, -17.495824, 0.074046, 0.623405,\n",
    "     -0.354081, 0.280695, 0.715854, -17.495824, -0.037227, -0.030303, -0.065959]\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# Create an array for the x-axis positions\n",
    "position = np.arange(len(kpi_names))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a scatter plot for each model with different colors\n",
    "#plt.scatter(position, actual_values, label=f'Actual', marker='o', s=100)\n",
    "for i, model_name in enumerate(models):\n",
    "    \n",
    "    plt.scatter(position, predicted_values[i], label=f'({model_name})', marker='x', s=100)\n",
    "\n",
    "# Set X-axis labels to KPI names\n",
    "plt.xticks(position, kpi_names, rotation=90)\n",
    "\n",
    "# Add labels and a reference line\n",
    "plt.ylabel('Values')\n",
    "plt.title('R square for KPIs (Multiple Models)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c5807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
